# ğŸ¡ **California House Price Prediction: An End-to-End Machine Learning Project**  
**Author:** Shrunali Salian  
**Skills:** Data Preprocessing, Feature Engineering, Regression Models, Scikit-Learn  

---

## ğŸš€ **Project Overview**  
This project is inspired by **Chapter 2** of *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by AurÃ©lien GÃ©ron. The goal is to **build a machine learning model that predicts house prices in California** based on real-world housing data.  

This project covers the **entire machine learning pipeline**, including:  
âœ… **Data Collection & Preprocessing** â€“ Handling missing values, feature scaling  
âœ… **Exploratory Data Analysis (EDA)** â€“ Visualizing key housing trends  
âœ… **Feature Engineering** â€“ Transforming raw data into meaningful predictors  
âœ… **Model Selection & Training** â€“ Comparing multiple regression models  
âœ… **Hyperparameter Tuning** â€“ Optimizing model performance  

ğŸ“Œ **Reference Repository:** [GitHub - AurÃ©lien GÃ©ron](https://github.com/ageron/handson-ml2)  

---

## ğŸ¯ **Key Objectives**  
âœ” **Develop a predictive model for house prices**  
âœ” **Perform in-depth data analysis & feature selection**  
âœ” **Compare different machine learning algorithms**  
âœ” **Optimize model performance using cross-validation & fine-tuning**  

---

## ğŸ“Š **Dataset Overview**  
The **California Housing Dataset** contains housing market information, including:  
- ğŸ“ **Geographical Features** â€“ Latitude, Longitude  
- ğŸ  **Housing Characteristics** â€“ Number of rooms, bedrooms, population  
- ğŸ’° **Median Income & House Value** â€“ Key economic indicators  

âœ… **Example: Loading the Dataset**  
```python
import pandas as pd

housing = pd.read_csv("housing.csv")
housing.head()
```

âœ… **Example: Checking for Missing Values**  
```python
housing.info()
```
ğŸ’¡ **Observation:** Some columns, like `total_bedrooms`, have missing values.  

---

## ğŸ“ˆ **Exploratory Data Analysis (EDA)**  
Before training the model, we analyze the data distribution and key insights.  

âœ… **Example: Visualizing Geographical Data**  
```python
import matplotlib.pyplot as plt

housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4,
             s=housing["population"]/100, label="Population",
             c="median_house_value", cmap=plt.get_cmap("jet"), colorbar=True)
plt.legend()
plt.show()
```
ğŸ’¡ **Insight:** Coastal regions tend to have **higher house prices**.  

âœ… **Example: Correlation Analysis**  
```python
corr_matrix = housing.corr()
corr_matrix["median_house_value"].sort_values(ascending=False)
```
ğŸ’¡ **Key Observations:**  
- **Median Income is highly correlated** with house prices.  
- **Number of Rooms also has a positive correlation** with house value.  

---

## ğŸ— **Feature Engineering & Data Preprocessing**  
We transform the data to improve model performance.  

âœ… **Handling Missing Values**  
```python
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy="median")
housing_num = housing.drop("ocean_proximity", axis=1)
imputer.fit(housing_num)
housing_num_imputed = imputer.transform(housing_num)
```
ğŸ’¡ **Why?** â€“ Missing values in `total_bedrooms` are replaced with the median.  

âœ… **Creating New Features**  
```python
housing["rooms_per_household"] = housing["total_rooms"] / housing["households"]
housing["bedrooms_per_room"] = housing["total_bedrooms"] / housing["total_rooms"]
```
ğŸ’¡ **Why?** â€“ Feature engineering **captures meaningful relationships** between variables.  

---

## ğŸ¤– **Model Training & Evaluation**  
We compare different **regression models** for price prediction.  

### **Baseline Models:**  
âœ… **Linear Regression**  
```python
from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, housing_labels)
```
âœ… **Decision Tree Regression**  
```python
from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor()
tree_reg.fit(housing_prepared, housing_labels)
```
âœ… **Random Forest Regression**  
```python
from sklearn.ensemble import RandomForestRegressor

forest_reg = RandomForestRegressor(n_estimators=100)
forest_reg.fit(housing_prepared, housing_labels)
```
ğŸ’¡ **Why Multiple Models?** â€“ Each regression model **has strengths & weaknesses**; comparing them **helps find the best one**.  

---

## ğŸ“Š **Model Evaluation & Performance Metrics**  
We evaluate models using:  
âœ” **Root Mean Squared Error (RMSE)** â€“ Measures prediction accuracy  
âœ” **Cross-Validation (K-Fold CV)** â€“ Ensures generalization  
âœ” **Hyperparameter Tuning (GridSearchCV)** â€“ Finds the best model settings  

âœ… **Example: RMSE Calculation**  
```python
from sklearn.metrics import mean_squared_error

predictions = lin_reg.predict(housing_prepared)
rmse = mean_squared_error(housing_labels, predictions, squared=False)
print(f"Linear Regression RMSE: {rmse}")
```
âœ… **Example: Cross-Validation for Model Selection**  
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(tree_reg, housing_prepared, housing_labels,
                         scoring="neg_mean_squared_error", cv=10)
rmse_scores = np.sqrt(-scores)
print(f"Decision Tree RMSE: {rmse_scores.mean()}")
```
ğŸ’¡ **Finding:** **Random Forest performed the best**, reducing RMSE significantly.  

âœ… **Example: Hyperparameter Tuning with GridSearchCV**  
```python
from sklearn.model_selection import GridSearchCV

param_grid = [
    {"n_estimators": [50, 100, 150], "max_features": [8, 10, 12]},
]

grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring="neg_mean_squared_error")
grid_search.fit(housing_prepared, housing_labels)
grid_search.best_params_
```
ğŸ’¡ **Why?** â€“ Hyperparameter tuning **optimizes model performance**.  

---

## ğŸ”® **Future Enhancements**  
ğŸ”¹ **Deploying the model** as a web app for real-time predictions  
ğŸ”¹ **Using Deep Learning (Neural Networks)** for better accuracy  
ğŸ”¹ **Feature Selection Optimization** using Recursive Feature Elimination (RFE)  

---

## ğŸ¯ **Why This Project Stands Out for ML & Data Science Roles**  
âœ” **End-to-End Machine Learning Pipeline** â€“ Covers all steps from data to model tuning  
âœ” **Compares Multiple Regression Models** â€“ Linear Regression, Decision Trees, Random Forests  
âœ” **Strong Feature Engineering & EDA** â€“ Key insights for better predictions  
âœ” **Demonstrates Model Optimization** â€“ Hyperparameter tuning improves accuracy  

---

## ğŸ›  **How to Run This Project**  
1ï¸âƒ£ Clone the repo:  
   ```bash
   git clone https://github.com/shrunalisalian/california-house-price-prediction.git
   ```
2ï¸âƒ£ Install dependencies:  
   ```bash
   pip install -r requirements.txt
   ```
3ï¸âƒ£ Run the Jupyter Notebook:  
   ```bash
   jupyter notebook "California House Price Prediction.ipynb"
   ```

---

## ğŸ“Œ **Connect with Me**  
- **LinkedIn:** [Shrunali Salian](https://www.linkedin.com/in/shrunali-salian/)  
- **Portfolio:** [Your Portfolio Link](#)  
- **Email:** [Your Email](#)  
